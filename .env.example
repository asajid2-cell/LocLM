# LLM Provider Configuration
# Options: groq, ollama, openai
LLM_PROVIDER=groq

# Groq API Configuration
# Get your API key from: https://console.groq.com
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Ollama Configuration (for local models)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# OpenAI Configuration (optional)
# OPENAI_API_KEY=your_openai_api_key_here
